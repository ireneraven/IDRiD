{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNet-Retina.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvFXa41qYK5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout, Lambda\n",
        "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
        "from tensorflow.keras.layers  import Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers  import MaxPooling2D, GlobalMaxPool2D\n",
        "from tensorflow.keras.layers  import concatenate, add\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COlnoCLKZZlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For loading our files from our google drive account:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWxGuzfDZtNn",
        "colab_type": "text"
      },
      "source": [
        "Definimos la U-Net\n",
        "![texto alternativo](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8rvSd1uZhm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#UNet code:\n",
        "# 1) Since each block consicts on two convolutions:\n",
        "\n",
        "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
        "    # first layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(input_tensor)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    # second layer\n",
        "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
        "               padding=\"same\")(x)\n",
        "    if batchnorm:\n",
        "        x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "# 2) We create a function to define the UNET Model\n",
        "def get_unet(inputs, n_filters=32, dropout=0.5, batchnorm=True):\n",
        "    # contracting path\n",
        "    c1 = conv2d_block(inputs, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "    p1 = Dropout(dropout*0.5)(p1)\n",
        "\n",
        "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "    p2 = Dropout(dropout)(p2)\n",
        "\n",
        "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "    p3 = Dropout(dropout)(p3)\n",
        "\n",
        "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "    p4 = Dropout(dropout)(p4)\n",
        "    \n",
        "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
        "    \n",
        "    # expansive path\n",
        "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    u6 = Dropout(dropout)(u6)\n",
        "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    u7 = Dropout(dropout)(u7)\n",
        "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    u8 = Dropout(dropout)(u8)\n",
        "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
        "\n",
        "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    u9 = Dropout(dropout)(u9)\n",
        "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
        "    \n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bTfYUggZ7VG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "print(\"Num GPUs Available: \", len(gpus))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWXn4M0eZ-mW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if len(gpus) >= 1:\n",
        "  config = tf.compat.v1.ConfigProto()\n",
        "  config.gpu_options.allow_growth = True\n",
        "  tf.compat.v1.Session(config = config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7i8GQUgaJUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#In this line we willspecify the UNet what it should expect\n",
        "\n",
        "# Specifying the input shape\n",
        "input_shape = Input((512, 512, 3), dtype = 'float32')\n",
        "\n",
        "model = get_unet(input_shape, n_filters=32, dropout=0.1, batchnorm=True)\n",
        "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX4B5649aV54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading our arrays saved as npy\n",
        "#In order for this to work you should write your own corresponding paths\n",
        "\n",
        "X_train = np.load('X_train_path.npy')\n",
        "y_train_MASK= np.load('y_train_MASK_path.npy')\n",
        "\n",
        "X_test = np.load('X_test_PATH.npy')\n",
        "y_test_MASK = np.load('/y_test_MASK_path.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqm-PzuAatsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Just for checking that everything was uploaded without any problems\n",
        "#The dimensions of X_train = y_train_MASK and the dimensions of X_test = y_test_MASK\n",
        "\n",
        "print(X_train.shape, y_train_MASK.shape, X_test.shape, y_test_MASK.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdl2d702bFWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For training the model.\n",
        "# We use some callbacks in order to avoid overfitting y underfitting, and additionally to save our best model.\n",
        "#Change the paths for each mask.\n",
        "\n",
        "modelCallbacks = [\n",
        "    EarlyStopping(monitor = 'val_loss', patience=10, verbose=1),\n",
        "    ReduceLROnPlateau(monitor = 'val_loss', factor=0.2, patience=6 , min_lr=0.00001, verbose=1),\n",
        "    ModelCheckpoint('path/model-MASK.h5', verbose=1, save_best_only=True, save_weights_only=True),\n",
        "    TensorBoard(log_dir = 'path/MASK/logs/MASK_1')\n",
        "    ]\n",
        "\n",
        "\n",
        "results = model.fit(X_train, y_train_MASK, batch_size= 16, epochs=100, verbose = 2, callbacks=modelCallbacks, validation_data=(X_test, y_test_MASK))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk8yK37Tbimz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot the learning curve and mark the best model:\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Learning curve\")\n",
        "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"log_loss\")\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvAe7ZZgbrul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now load weights from the best saved model:\n",
        "# Note that the exact same path that was saved in the callback modelcheckpoint must be written.\n",
        "\n",
        "model.load_weights('path/model-MASK.h5')\n",
        "\n",
        "# Evaluate on test set.\n",
        "model.evaluate(X_test, y_test_MASK, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDiy_arZcH8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check the max value from a random pred train, it is usedfull for choosing the threshold in the next step\n",
        "\n",
        "print(np.amin(preds_test[16]),np.amax(preds_test[16]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFFvrdpicTpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0fk3dupcZ-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Used to plot the original image, the original mask, the UNet predicted mask and the UNet predicted binary mask\n",
        "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
        "  plt.imshow(X[ix],cmap='gray')\n",
        "  plt.xticks([]), plt.yticks([])  \n",
        "  plt.xlabel('Retina image')\n",
        "  plt.show()\n",
        "\n",
        "  plt.imshow(y[ix].squeeze(), cmap='gray',vmin=0,vmax=1)\n",
        "  plt.xticks([]), plt.yticks([])  \n",
        "  plt.xlabel('Original mask')\n",
        "  plt.show()\n",
        "\n",
        "  plt.imshow(preds[ix].squeeze(), cmap='gray')\n",
        "  plt.xticks([]), plt.yticks([])  \n",
        "  plt.xlabel('Mask prediction')\n",
        "  plt.show()\n",
        "\n",
        "  plt.imshow(binary_preds[ix].squeeze(), cmap='gray',vmin=0,vmax=1)\n",
        "  plt.xticks([]), plt.yticks([])  \n",
        "  plt.xlabel('Binary mask prediction')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM96YmKwcdru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now lets plot some samples from the train set:\n",
        "# Bear in mind that ix should be a number\n",
        "\n",
        "plot_sample(X_train, y_train_MASK, preds_train, preds_train_t, ix= X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mmUc4hWc16n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now lets plot some samples from the test set:\n",
        "# Bear in mind that ix should be a number\n",
        "\n",
        "plot_sample(X_train, y_test_MASK, preds_test, preds_test_t, ix= X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYeb-Fwmc594",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}